{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "995b3f7e-4c77-475f-93f6-d7e5dc8d8d0f",
   "metadata": {},
   "source": [
    "## Loading in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2551deb-8790-47a3-afef-66e243dd49be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "df = pd.read_csv(\"Hourly_Elec_Full_Finished_compleet.xls\", sep=',', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d453b207-47a7-4fd8-9c2b-d3174779eaed",
   "metadata": {},
   "source": [
    "## Column naming consistency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12021428-59bb-4169-b456-a216fc6bbc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making lowercase column names for consistency\n",
    "df.columns = [c.lower() for c in df.columns]\n",
    "\n",
    "# ensuring datetime_hour column exists and is datetime\n",
    "df['datetime_hour'] = pd.to_datetime(df['datetime_hour'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9842197-4eb2-4a62-bf0a-207e7059f79a",
   "metadata": {},
   "source": [
    "## Filling missing values of Spotprices and Regional energy production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6ec781-8130-46c4-8608-3982f419c8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resolving problem of having energy spotprice and NaNs of region production to 0\n",
    "if 'spot_price_elec_mw' in df.columns:\n",
    "    df['spot_price_elec_mw'] = df.groupby('datetime_hour')['spot_price_elec_mw'].transform(\n",
    "        lambda x: x.fillna(x.mean()))\n",
    "    df['spot_price_elec_mw'] = df['spot_price_elec_mw'].ffill().bfill()\n",
    "\n",
    "# Filling energy columns with NaNs with 0\n",
    "energy_columns = ['thermique', 'nucléaire', 'eolien', 'solaire', 'hydraulique', 'pompage', 'bioénergies']\n",
    "energy_columns = [c.lower() for c in energy_columns]\n",
    "for col in energy_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f94627-d042-447d-aa92-28c9cfd74681",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc645573-5152-4dfe-9a83-b6fe25247574",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature engineering for additional features\n",
    "df['hour'] = df['datetime_hour'].dt.hour\n",
    "df['day_of_week'] = df['datetime_hour'].dt.dayofweek\n",
    "df['month'] = df['datetime_hour'].dt.month\n",
    "df['is_weekend'] = (df['day_of_week'] >= 5).astype('uint8')\n",
    "df['week_of_year'] = df['datetime_hour'].dt.isocalendar().week.astype('int8')\n",
    "\n",
    "#Creating lag  and rolling mean featurss of spot prices\n",
    "BASE_PRICE = 36.56\n",
    "\n",
    "# replacing the first missing values of spot price with the base price \n",
    "def safe_lag(series, periods):\n",
    "    lagged = series.shift(periods)\n",
    "    lagged.iloc[:periods] = BASE_PRICE  \n",
    "    return lagged.fillna(BASE_PRICE)\n",
    "\n",
    "# calculating the rolling average prices and replace any missing values with the base price\n",
    "def safe_rolling_mean(series, window):\n",
    "    roll = series.rolling(window=window, min_periods=1).mean()\n",
    "    return roll.fillna(BASE_PRICE)\n",
    "\n",
    "\n",
    "# add lagged features for spot prices\n",
    "if 'spot_price_elec_mw' in df.columns:\n",
    "    df[\"spot_price_1h\"] = safe_lag(df[\"spot_price_elec_mw\"], 1)\n",
    "    df[\"spot_price_24h\"] = safe_lag(df[\"spot_price_elec_mw\"], 24)\n",
    "    df[\"spot_price_7d\"] = safe_lag(df[\"spot_price_elec_mw\"], 24*7)\n",
    "\n",
    "    # adding rolling averages for spot prices\n",
    "    df[\"prev_daily_avg_spot_price\"] = safe_rolling_mean(df[\"spot_price_elec_mw\"], 24)\n",
    "    df[\"prev_week_avg_spot_price\"] = safe_rolling_mean(df[\"spot_price_elec_mw\"], 24*7)\n",
    "    df[\"prev_month_avg_spot_price\"] = safe_rolling_mean(df[\"spot_price_elec_mw\"], 24*30)\n",
    "\n",
    "#Creating season column \n",
    "def get_season(m):\n",
    "    if m in [12,1,2]:\n",
    "        return 'winter'\n",
    "    if m in [3,4,5]:\n",
    "        return 'spring'\n",
    "    if m in [6,7,8]:\n",
    "        return 'summer'\n",
    "    return 'autumn'\n",
    "\n",
    "df['season'] = df['month'].apply(get_season)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56638785-afb2-437d-bfab-5ef86c326e57",
   "metadata": {},
   "source": [
    "## One-hot encoding exogenous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba69441-72e8-43af-9438-9f5a0b5f0fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating one-hot encoded features for the models\n",
    "categorical_cols = [c for c in ['school_zone', 'vacation_name', 'holiday_name', 'season'] if c in df.columns]\n",
    "if categorical_cols:\n",
    "    df[categorical_cols] = df[categorical_cols].astype('category')\n",
    "    df = pd.get_dummies(df, columns=categorical_cols, prefix=categorical_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55981639-4fa9-47b8-8123-bc7d4c33371b",
   "metadata": {},
   "source": [
    "## Fixing name consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aa8c2c-5050-48e9-a4bc-c2762ba62c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing the names for the columns\n",
    "def clean_col(col):\n",
    "    col = col.lower()\n",
    "    col = col.replace(\" \", \"_\")\n",
    "    col = re.sub(r\"[^\\w\\d_]\", \"\", col)\n",
    "    return col\n",
    "\n",
    "df.columns = [clean_col(c) for c in df.columns]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ac4da9-d8c3-4f04-a7f2-c36e4f92152b",
   "metadata": {},
   "source": [
    "## Additional fixing of features type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aa8409-2fc3-4867-9d26-5c34e08bb2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Giving categorization for insee reigon and weather code\n",
    "for c in ['insee_region', 'weather_code']:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9087fead-e147-444b-bf74-daa8c9717b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making sure the dataset is optimalized so it is less computational expensive for the models to run \n",
    "\n",
    "int_cols = df.select_dtypes(include=['int64']).columns\n",
    "if len(int_cols) > 0:\n",
    "    df[int_cols] = df[int_cols].apply(pd.to_numeric, downcast='integer')\n",
    "\n",
    "float_cols = df.select_dtypes(include=['float64']).columns\n",
    "if len(float_cols) > 0:\n",
    "    df[float_cols] = df[float_cols].astype('float32')\n",
    "\n",
    "bool_cols = df.select_dtypes(include=['bool']).columns\n",
    "if len(bool_cols) > 0:\n",
    "    df[bool_cols] = df[bool_cols].astype('uint8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af54cc3e-1936-4132-93e7-cd92f2197352",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Refixing a issue of column disposable income that is not properly tranferred\n",
    "if 'disposable_income' in df.columns:\n",
    "    df['disposable_income'] = pd.to_numeric(df['disposable_income'], errors='coerce').astype('float32')\n",
    "\n",
    "df.rename(columns={'gdp_per employment': 'gdp_per_employment'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8b18c5-2134-4295-ac3b-21c684e4662e",
   "metadata": {},
   "source": [
    "## Removing correlated feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde6bbf1-6b12-4f76-8f41-c244ad944ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing columns after checking the correlation being above 0.8\n",
    "keep_cols = [\n",
    "    \"datetime_hour\", \"insee_region\", \"conso_elec_mw\", \"conso_gaz_mw\",\n",
    "    \"temperature_2m\", \"relative_humidity_2m\", \"pressure_msl\", \"surface_pressure\",\n",
    "    \"rain\", \"snowfall\", \"cloud_cover\", \"cloud_cover_low\", \"cloud_cover_mid\", \"cloud_cover_high\",\n",
    "    \"shortwave_radiation\", \"diffuse_radiation\", \"sunshine_duration\",\n",
    "    \"wind_speed_10m\", \"wind_direction_10m\", \"weather_code\", \"snow_depth\",\n",
    "    \"soil_moisture_0_to_7cm\", \"year\", \"quarter\", \"hour\", \"day_of_week\", \"month\", \"is_weekend\"\n",
    "]\n",
    "keep_cols = [c for c in keep_cols if c in df.columns]\n",
    "\n",
    "print(\"Duplicates included:\", df.shape)\n",
    "df = df.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4e4d94-7481-497a-a781-ecee6427c289",
   "metadata": {},
   "source": [
    "## Filteren and saving the datasets for experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6c34e2-a633-4f45-ace2-2787eb2c2fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filteren the years and checking the additional data with removing the correlared features\n",
    "df_2015_2019 = df[(df['datetime_hour'].dt.year >= 2015) & (df['datetime_hour'].dt.year <= 2019)].copy()\n",
    "\n",
    "cols_all_minus_desc = [c for c in df_2015_2019.columns if c not in ['region_name', 'weather_desc']]\n",
    "df_additional = df_2015_2019[cols_all_minus_desc].copy()\n",
    "\n",
    "cols_to_remove = [\"region_name\", \"weather_desc\",\n",
    "                  \"precipitation\", \"dew_point_2m\", \"apparent_temperature\", \"pressure_msl\",\n",
    "                  \"wind_speed_100m\", \"wind_direction_100m\", \"wind_gusts_10m\", \"et0_fao_evapotranspiration\"]\n",
    "cols_to_remove = [c for c in cols_to_remove if c in df_additional.columns]\n",
    "\n",
    "df_additional.drop(columns=cols_to_remove, inplace=True)\n",
    "df_additional['datetime_hour'] = pd.to_datetime(df_additional['datetime_hour'])\n",
    "df_additional['week_of_year'] = df_additional['datetime_hour'].dt.isocalendar().week.astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c31a35a-abea-49b3-8a61-ea5989bcb853",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the datasets to use for further use\n",
    "\n",
    "#Basic dataset\n",
    "df_original_data = df_2015_2019[keep_cols + ['week_of_year']].copy()\n",
    "df_original_data.to_csv(\"Hourly_Elec_Original_Data.csv\", index=False, date_format='%Y-%m-%d %H:%M:%S')\n",
    "df_original_data.to_pickle(\"Hourly_Elec_Original_Data.pkl\")\n",
    "\n",
    "\n",
    "#Enriched dataset\n",
    "df_additional.to_csv(\"Hourly_Elec_Additional_Data.csv\", index=False, date_format='%Y-%m-%d %H:%M:%S')\n",
    "df_additional.to_pickle(\"Hourly_Elec_Additional_Data.pkl\")\n",
    "\n",
    "#EDA daataset\n",
    "eda_extra = [c for c in [\"region_name\", \"weather_desc\"] if c in df_2015_2019.columns]\n",
    "eda_cols = keep_cols + eda_extra\n",
    "\n",
    "df_eda = df_2015_2019[eda_cols + [\"week_of_year\"]].copy()\n",
    "df_eda.to_csv(\"Hourly_Elec_Original_EDA.csv\", index=False, date_format='%Y-%m-%d %H:%M:%S')\n",
    "df_eda.to_pickle(\"Hourly_Elec_Original_EDA.pkl\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
