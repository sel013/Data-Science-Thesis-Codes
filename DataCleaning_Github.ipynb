{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48d4d162-5452-4063-8a3d-e693c65baf3d",
   "metadata": {},
   "source": [
    "## loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2f8bdd-3b14-4ca1-9459-396a7489a258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('merged_hourly_regional.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c727c9-36a1-49e4-a6c9-5cf1a2f501ce",
   "metadata": {},
   "source": [
    "## Defining region names and weather codes for better understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1537673f-8e00-45ee-8041-b60fedae777f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I define the region names here so I can replace the numeric INSEE codes with something readable\n",
    "region_map = {\n",
    "    11: \"Île-de-France\",\n",
    "    24: \"Centre-Val de Loire\",\n",
    "    27: \"Bourgogne-Franche-Comté\",\n",
    "    28: \"Normandie\",\n",
    "    32: \"Hauts-de-France\",\n",
    "    44: \"Grand Est\",\n",
    "    52: \"Pays de la Loire\",\n",
    "    53: \"Bretagne\",\n",
    "    75: \"Nouvelle-Aquitaine\",\n",
    "    76: \"Occitanie\",\n",
    "    84: \"Auvergne-Rhône-Alpes\",\n",
    "    93: \"Provence-Alpes-Côte d’Azur\"\n",
    "}\n",
    "\n",
    "# I  define descriptions for each weather code here so they are  easier to interpret later\n",
    "weather_map = {\n",
    "    0: \"Clear sky\",\n",
    "    1: \"Mainly clear\",\n",
    "    2: \"Partly cloudy\",\n",
    "    3: \"Overcast\",\n",
    "    51: \"Drizzle: Light intensity\",\n",
    "    53: \"Drizzle: Moderate intensity\",\n",
    "    55: \"Drizzle: Dense intensity\",\n",
    "    61: \"Rain: Slight intensity\",\n",
    "    63: \"Rain: Moderate intensity\",\n",
    "    65: \"Rain: Heavy intensity\",\n",
    "    71: \"Snow fall: Slight intensity\",\n",
    "    73: \"Snow fall: Moderate intensity\",\n",
    "    75: \"Snow fall: Heavy intensity\"\n",
    "}\n",
    "\n",
    "# Here I am applying the mapping dictionaries and turning these columns into categorical types\n",
    "df[\"region_name\"] = df[\"insee_region\"].map(region_map).astype(\"category\")\n",
    "df[\"insee_region\"] = df[\"insee_region\"].astype(\"category\")\n",
    "\n",
    "df[\"weather_desc\"] = df[\"weather_code\"].map(weather_map).astype(\"category\")\n",
    "df[\"weather_code\"] = df[\"weather_code\"].astype(\"category\")\n",
    "\n",
    "# I reorder the columns so that the descriptive fields sit right next to their corresponding codes\n",
    "cols = df.columns.tolist()\n",
    "\n",
    "insee_idx = cols.index(\"insee_region\")\n",
    "cols.insert(insee_idx + 1, cols.pop(cols.index(\"region_name\")))\n",
    "\n",
    "weather_idx = cols.index(\"weather_code\")\n",
    "cols.insert(weather_idx + 1, cols.pop(cols.index(\"weather_desc\")))\n",
    "\n",
    "df = df[cols]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d511b9d9-3308-48df-8a6d-af50b9605882",
   "metadata": {},
   "source": [
    "## dropping redundant date columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50281a8a-1ee4-4a60-894e-22777467e395",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DROPPING REDUNT DATE AND DATETIME COLUMN\n",
    "df = df.drop(columns=[\"date\", \"datetime\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a0e25d-9518-4560-b44a-4e9717ee73c2",
   "metadata": {},
   "source": [
    "## Checking electricity load and  weather values are in valid ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b190e7d-9e48-4e80-888b-df0d722570af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING WEATHER VALUES IN VALID RANGE\n",
    "print(\"Relative humidity out of range:\")\n",
    "print(df[(df[\"relative_humidity_2m\"] < 0) | (df[\"relative_humidity_2m\"] > 100)].shape)\n",
    "\n",
    "print(\"Cloud cover out of range:\")\n",
    "cloud_cols = [\"cloud_cover\", \"cloud_cover_low\", \"cloud_cover_mid\", \"cloud_cover_high\"]\n",
    "for col in cloud_cols:\n",
    "    out_of_range = df[(df[col] < 0) | (df[col] > 100)]\n",
    "    print(f\"{col}: {out_of_range.shape[0]} rows out of range\")\n",
    "\n",
    "# I check the wind direction here since it must stay between 0 and 360 degrees\n",
    "wind_cols = [\"wind_direction_10m\", \"wind_direction_100m\"]\n",
    "for col in wind_cols:\n",
    "    out_of_range = df[(df[col] < 0) | (df[col] > 360)]\n",
    "    print(f\"{col}: {out_of_range.shape[0]} rows out of range\")\n",
    "\n",
    "# I check that precipitation related values are not negative\n",
    "precip_cols = [\"precipitation\", \"rain\", \"snowfall\", \"snow_depth\"]\n",
    "for col in precip_cols:\n",
    "    negative_values = df[df[col] < 0]\n",
    "    print(f\"{col}: {negative_values.shape[0]} rows with negative values\")\n",
    "\n",
    "\n",
    "# I check for impossible electricity consumption values here\n",
    "invalid_elec = df[df[\"conso_elec_mw\"] <= 0]\n",
    "print(\"Number of rows with non-positive electricity consumption:\", invalid_elec.shape[0])\n",
    "print(invalid_elec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3824a1af-2982-4167-a1e7-0f91009919b8",
   "metadata": {},
   "source": [
    "## dropping invalid electricity rows and saving to new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f587a878-c7f3-4c46-8b3f-5271e9192095",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DROPPING ALL ROWS WHERE ELEC IS 0 OR BELOW 0 \n",
    "df_clean = df[df[\"conso_elec_mw\"] > 0].copy()\n",
    "\n",
    "print(\"Original shape:\", df.shape)\n",
    "print(\"New shape after dropping non-positive electricity rows:\", df_clean.shape)\n",
    "\n",
    "\n",
    "#CONVERTIG DATETIME_HOUR to datetime for further use\n",
    "df_clean[\"datetime_hour\"] = pd.to_datetime(df_clean[\"datetime_hour\"])\n",
    "\n",
    "\n",
    "#SAVE Dataframe to a new clean CSV\n",
    "df_clean.to_csv(\"Hourly_Elec_Cleaned.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f71bfc-eae7-4f6f-b8a9-ede9729196dc",
   "metadata": {},
   "source": [
    "## Creating pickle file to make sure categorical features are preserved categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda6e313-1d11-435c-885a-0a61b5a2545f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATING PICKLE FILE TO PRESERVE FORMAT\n",
    "# I  convert the categorical fields again here to make sure they stay preserved inside the pickle\n",
    "categorical_cols = [\"region_name\", \"weather_desc\", \"insee_region\", \"weather_code\"]\n",
    "for col in categorical_cols:\n",
    "    df1[col] = df1[col].astype(\"category\")\n",
    "\n",
    "df1[\"datetime_hour\"] = pd.to_datetime(df1[\"datetime_hour\"])\n",
    "\n",
    "df1.to_pickle(\"Hourly_Elec_Cleaned.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "df2 = pd.read_pickle(\"Hourly_Elec_Cleaned.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
